{
  "pipelineSpec": {
    "components": {
      "comp-db-search": {
        "executorLabel": "exec-db-search",
        "inputDefinitions": {
          "parameters": {
            "database_paths": {
              "type": "STRING"
            },
            "datasets_disk_image": {
              "type": "STRING"
            },
            "fasta_path": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            },
            "search_tool": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_msa": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-db-search": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "db_search"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef db_search(\n    project: str,\n    region: str,\n    datasets_disk_image: str,\n    database_paths: str,\n    fasta_path: str,\n    search_tool: str,\n    output_msa: Output[Artifact], \n    tool_options: dict=None):\n    \"\"\"Searches sequence databases using the specified tool.\n\n    This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n    We are using CLS as KFP does not support attaching pre-populated disks or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch or hhblits.\n\n    \"\"\"\n\n    import logging\n\n    from alphafold_components import dsub_wrapper\n\n    # For a prototype we are hardcoding some values. Whe productionizing\n    # we can make them compile time or runtime parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2 instruction set\n    # Works better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\n    _REFERENCE_DATASETS_IMAGE = \"https://www.googleapis.com/compute/v1/projects/jk-mlops-dev/global/images/jk-alphafold-datasets 3000\"\n    _TOOL_TO_SETTINGS_MAPPING = {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-8',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 6,\n           'MAX_STO_SEQUENCES': '10_000',\n           'FILE_FORMAT': 'sto'\n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-8',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 6,\n           'FILE_FORMAT': 'a3m'\n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-8',\n           'BOOT_DISK_SIZE': '200',\n           'MAXSEQ': '1_000_000',\n           'FILE_FORMAT': 'hhr'\n       }\n    }\n\n    if not search_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n        raise ValueError(f'Unsupported tool: {search_tool}')\n    # We should probably also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _SCRIPT = './msa_runner.py'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\n\n    # This is a temporary hack till we find a better option for dsub logging location\n    # It would be great if we can access pipeline root directly\n    # If not we can always pass the location as a parameter \n    logging_gcs_path = output_msa.uri.split('/')[2:-2]\n    folders = '/'.join(logging_gcs_path)\n    logging_gcs_path = f'gs://{folders}/logging'\n    file_format = _TOOL_TO_SETTINGS_MAPPING[search_tool].pop('FILE_FORMAT') \n\n    dsub_job = dsub_wrapper.DsubJob(\n        image=_IMAGE,\n        project=project,\n        region=region,\n        logging=logging_gcs_path,\n        provider=_DSUB_PROVIDER,\n        machine_type=_TOOL_TO_SETTINGS_MAPPING[search_tool].pop('MACHINE_TYPE'),\n        boot_disk_size=_TOOL_TO_SETTINGS_MAPPING[search_tool].pop('BOOT_DISK_SIZE'),\n        log_interval=_LOG_INTERVAL\n    )\n\n    inputs = {\n        'FASTA_PATH': fasta_path, \n    }\n    outputs = {\n        'OUTPUT_DIR': output_msa.uri,\n    }\n    env_vars = {\n        'PYTHONPATH': '/app/alphafold',\n        'DATABASE_PATHS': database_paths,\n        'MSA_TOOL': search_tool,\n    }\n    env_vars.update(_TOOL_TO_SETTINGS_MAPPING[search_tool])\n\n    if not datasets_disk_image:\n        datasets_disk_image = _REFERENCE_DATASETS_IMAGE\n\n    disk_mounts = {\n        'DATABASES_ROOT': datasets_disk_image \n    }\n\n    logging.info('Starting a dsub job')\n    # Right now this is a blocking call. In future we should implement\n    # a polling loop to periodically retrieve logs, stdout and stderr\n    # and push it Vertex\n    result = dsub_job.run_job(\n        script=_SCRIPT,\n        inputs=inputs,\n        outputs=outputs,\n        env_vars=env_vars,\n        disk_mounts=disk_mounts\n    )\n\n    logging.info('Job completed')\n    logging.info(f'Completion status {result.returncode}')\n    logging.info(f'Logs: {result.stdout}')\n\n    if result.returncode != 0:\n        raise RuntimeError('dsub job failed')\n\n    output_msa.metadata['file_format']=file_format\n\n"
            ],
            "image": "gcr.io/jk-mlops-dev/alphafold-components"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "alphafold-inference"
    },
    "root": {
      "dag": {
        "tasks": {
          "db-search": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-db-search"
            },
            "inputs": {
              "parameters": {
                "database_paths": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "uniref90/uniref90.fasta"
                    }
                  }
                },
                "datasets_disk_image": {
                  "componentInputParameter": "datasets_disk_image"
                },
                "fasta_path": {
                  "componentInputParameter": "fasta_path"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "region": {
                  "componentInputParameter": "region"
                },
                "search_tool": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "jackhmmer"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "db-search"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "datasets_disk_image": {
            "type": "STRING"
          },
          "fasta_path": {
            "type": "STRING"
          },
          "project": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.11"
  },
  "runtimeConfig": {
    "parameters": {
      "datasets_disk_image": {
        "stringValue": "https://www.googleapis.com/compute/v1/projects/jk-mlops-dev/global/images/jk-alphafold-datasets 3000"
      },
      "project": {
        "stringValue": "jk-mlops-dev"
      },
      "region": {
        "stringValue": "us-central1"
      }
    }
  }
}