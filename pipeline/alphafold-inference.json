{
  "pipelineSpec": {
    "components": {
      "comp-db-search": {
        "executorLabel": "exec-db-search",
        "inputDefinitions": {
          "artifacts": {
            "input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "database_paths": {
              "type": "STRING"
            },
            "db_tool": {
              "type": "STRING"
            },
            "disk_image": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "cls_logging": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "output_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-db-search-2": {
        "executorLabel": "exec-db-search-2",
        "inputDefinitions": {
          "artifacts": {
            "input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "database_paths": {
              "type": "STRING"
            },
            "db_tool": {
              "type": "STRING"
            },
            "disk_image": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "cls_logging": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "output_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-db-search-3": {
        "executorLabel": "exec-db-search-3",
        "inputDefinitions": {
          "artifacts": {
            "input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "database_paths": {
              "type": "STRING"
            },
            "db_tool": {
              "type": "STRING"
            },
            "disk_image": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "cls_logging": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "output_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-db-search-4": {
        "executorLabel": "exec-db-search-4",
        "inputDefinitions": {
          "artifacts": {
            "input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "database_paths": {
              "type": "STRING"
            },
            "db_tool": {
              "type": "STRING"
            },
            "disk_image": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "region": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "cls_logging": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "output_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-importer": {
        "executorLabel": "exec-importer",
        "inputDefinitions": {
          "parameters": {
            "uri": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "artifact": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-db-search": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "db_search"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef db_search(\n    project: str,\n    region: str,\n    disk_image: str,\n    database_paths: str,\n    db_tool: str,\n    input_data: Input[Dataset],\n    output_data: Output[Dataset],\n    cls_logging: Output[Artifact] \n    ):\n    \"\"\"Searches sequence databases using the specified tool.\n\n    This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n    We are using CLS as KFP does not support attaching pre-populated disks or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch or hhblits.\n\n    \"\"\"\n\n\n    import logging\n    import os\n\n    from dsub_wrapper import run_dsub_job\n\n    # For a prototype we are hardcoding some values. Whe productionizing\n    # we can make them compile time or runtime parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2 instruction set\n    # Works better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\n    _TOOL_TO_SETTINGS_MAPPING = {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '10_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'sto',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'a3m',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 0, # Not setable for hhsearch\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'sto',\n           'OUTPUT_DATA_FORMAT': 'hhr',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       }\n    }\n\n    if not db_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n        raise ValueError(f'Unsupported tool: {db_tool}')\n    # We should probably also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\n    output_data.metadata['data_format'] = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\n    job_params = [\n        '--db_tool', db_tool,\n        '--machine-type', _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size', _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging', cls_logging.uri,\n        '--mount', f'DB_ROOT={disk_image}',\n        '--input', f'INPUT_DATA={input_data.uri}',\n        '--output', f'OUTPUT_DATA={output_data.uri}',\n        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"N_CPU\"]}',\n        '--env', f'INPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"INPUT_DATA_FORMAT\"]}', \n        '--env', f'OUTPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"OUTPUT_DATA_FORMAT\"]}', \n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT'] \n    ]\n\n    return\n\n    result = run_dsub_job(\n        provider='google-cls-v2',\n        project=project,\n        regions=region,\n        params=job_params,\n    ) \n\n"
            ],
            "image": "gcr.io/jk-mlops-dev/alphafold-components"
          }
        },
        "exec-db-search-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "db_search"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef db_search(\n    project: str,\n    region: str,\n    disk_image: str,\n    database_paths: str,\n    db_tool: str,\n    input_data: Input[Dataset],\n    output_data: Output[Dataset],\n    cls_logging: Output[Artifact] \n    ):\n    \"\"\"Searches sequence databases using the specified tool.\n\n    This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n    We are using CLS as KFP does not support attaching pre-populated disks or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch or hhblits.\n\n    \"\"\"\n\n\n    import logging\n    import os\n\n    from dsub_wrapper import run_dsub_job\n\n    # For a prototype we are hardcoding some values. Whe productionizing\n    # we can make them compile time or runtime parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2 instruction set\n    # Works better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\n    _TOOL_TO_SETTINGS_MAPPING = {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '10_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'sto',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'a3m',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 0, # Not setable for hhsearch\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'sto',\n           'OUTPUT_DATA_FORMAT': 'hhr',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       }\n    }\n\n    if not db_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n        raise ValueError(f'Unsupported tool: {db_tool}')\n    # We should probably also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\n    output_data.metadata['data_format'] = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\n    job_params = [\n        '--db_tool', db_tool,\n        '--machine-type', _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size', _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging', cls_logging.uri,\n        '--mount', f'DB_ROOT={disk_image}',\n        '--input', f'INPUT_DATA={input_data.uri}',\n        '--output', f'OUTPUT_DATA={output_data.uri}',\n        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"N_CPU\"]}',\n        '--env', f'INPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"INPUT_DATA_FORMAT\"]}', \n        '--env', f'OUTPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"OUTPUT_DATA_FORMAT\"]}', \n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT'] \n    ]\n\n    return\n\n    result = run_dsub_job(\n        provider='google-cls-v2',\n        project=project,\n        regions=region,\n        params=job_params,\n    ) \n\n"
            ],
            "image": "gcr.io/jk-mlops-dev/alphafold-components"
          }
        },
        "exec-db-search-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "db_search"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef db_search(\n    project: str,\n    region: str,\n    disk_image: str,\n    database_paths: str,\n    db_tool: str,\n    input_data: Input[Dataset],\n    output_data: Output[Dataset],\n    cls_logging: Output[Artifact] \n    ):\n    \"\"\"Searches sequence databases using the specified tool.\n\n    This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n    We are using CLS as KFP does not support attaching pre-populated disks or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch or hhblits.\n\n    \"\"\"\n\n\n    import logging\n    import os\n\n    from dsub_wrapper import run_dsub_job\n\n    # For a prototype we are hardcoding some values. Whe productionizing\n    # we can make them compile time or runtime parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2 instruction set\n    # Works better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\n    _TOOL_TO_SETTINGS_MAPPING = {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '10_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'sto',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'a3m',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 0, # Not setable for hhsearch\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'sto',\n           'OUTPUT_DATA_FORMAT': 'hhr',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       }\n    }\n\n    if not db_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n        raise ValueError(f'Unsupported tool: {db_tool}')\n    # We should probably also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\n    output_data.metadata['data_format'] = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\n    job_params = [\n        '--db_tool', db_tool,\n        '--machine-type', _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size', _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging', cls_logging.uri,\n        '--mount', f'DB_ROOT={disk_image}',\n        '--input', f'INPUT_DATA={input_data.uri}',\n        '--output', f'OUTPUT_DATA={output_data.uri}',\n        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"N_CPU\"]}',\n        '--env', f'INPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"INPUT_DATA_FORMAT\"]}', \n        '--env', f'OUTPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"OUTPUT_DATA_FORMAT\"]}', \n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT'] \n    ]\n\n    return\n\n    result = run_dsub_job(\n        provider='google-cls-v2',\n        project=project,\n        regions=region,\n        params=job_params,\n    ) \n\n"
            ],
            "image": "gcr.io/jk-mlops-dev/alphafold-components"
          }
        },
        "exec-db-search-4": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "db_search"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef db_search(\n    project: str,\n    region: str,\n    disk_image: str,\n    database_paths: str,\n    db_tool: str,\n    input_data: Input[Dataset],\n    output_data: Output[Dataset],\n    cls_logging: Output[Artifact] \n    ):\n    \"\"\"Searches sequence databases using the specified tool.\n\n    This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n    We are using CLS as KFP does not support attaching pre-populated disks or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch or hhblits.\n\n    \"\"\"\n\n\n    import logging\n    import os\n\n    from dsub_wrapper import run_dsub_job\n\n    # For a prototype we are hardcoding some values. Whe productionizing\n    # we can make them compile time or runtime parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2 instruction set\n    # Works better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\n    _TOOL_TO_SETTINGS_MAPPING = {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '10_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'sto',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT': 'a3m',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 0, # Not setable for hhsearch\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT': 'sto',\n           'OUTPUT_DATA_FORMAT': 'hhr',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py' \n       }\n    }\n\n    if not db_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n        raise ValueError(f'Unsupported tool: {db_tool}')\n    # We should probably also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\n    output_data.metadata['data_format'] = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\n    job_params = [\n        '--db_tool', db_tool,\n        '--machine-type', _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size', _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging', cls_logging.uri,\n        '--mount', f'DB_ROOT={disk_image}',\n        '--input', f'INPUT_DATA={input_data.uri}',\n        '--output', f'OUTPUT_DATA={output_data.uri}',\n        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"N_CPU\"]}',\n        '--env', f'INPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"INPUT_DATA_FORMAT\"]}', \n        '--env', f'OUTPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"OUTPUT_DATA_FORMAT\"]}', \n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT'] \n    ]\n\n    return\n\n    result = run_dsub_job(\n        provider='google-cls-v2',\n        project=project,\n        regions=region,\n        params=job_params,\n    ) \n\n"
            ],
            "image": "gcr.io/jk-mlops-dev/alphafold-components"
          }
        },
        "exec-importer": {
          "importer": {
            "artifactUri": {
              "runtimeParameter": "uri"
            },
            "typeSchema": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "alphafold-inference"
    },
    "root": {
      "dag": {
        "tasks": {
          "db-search": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-db-search"
            },
            "dependentTasks": [
              "importer"
            ],
            "inputs": {
              "artifacts": {
                "input_data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "artifact",
                    "producerTask": "importer"
                  }
                }
              },
              "parameters": {
                "database_paths": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "uniref90/uniref90.fasta"
                    }
                  }
                },
                "db_tool": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "jackhmmer"
                    }
                  }
                },
                "disk_image": {
                  "componentInputParameter": "datasets_disk_image"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "region": {
                  "componentInputParameter": "region"
                }
              }
            },
            "taskInfo": {
              "name": "Search Uniref"
            }
          },
          "db-search-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-db-search-2"
            },
            "dependentTasks": [
              "importer"
            ],
            "inputs": {
              "artifacts": {
                "input_data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "artifact",
                    "producerTask": "importer"
                  }
                }
              },
              "parameters": {
                "database_paths": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "mgnify/mgy_clusters_2018_12.fa"
                    }
                  }
                },
                "db_tool": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "jackhmmer"
                    }
                  }
                },
                "disk_image": {
                  "componentInputParameter": "datasets_disk_image"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "region": {
                  "componentInputParameter": "region"
                }
              }
            },
            "taskInfo": {
              "name": "Search Mgnify"
            }
          },
          "db-search-3": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-db-search-3"
            },
            "dependentTasks": [
              "importer"
            ],
            "inputs": {
              "artifacts": {
                "input_data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "artifact",
                    "producerTask": "importer"
                  }
                }
              },
              "parameters": {
                "database_paths": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "uniclust30/uniclust30_2018_08/uniclust30_2018_08,bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt"
                    }
                  }
                },
                "db_tool": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "hhblits"
                    }
                  }
                },
                "disk_image": {
                  "componentInputParameter": "datasets_disk_image"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "region": {
                  "componentInputParameter": "region"
                }
              }
            },
            "taskInfo": {
              "name": "Search Uniclust and BFD"
            }
          },
          "db-search-4": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-db-search-4"
            },
            "dependentTasks": [
              "db-search"
            ],
            "inputs": {
              "artifacts": {
                "input_data": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_data",
                    "producerTask": "db-search"
                  }
                }
              },
              "parameters": {
                "database_paths": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "pdb70/pdb70"
                    }
                  }
                },
                "db_tool": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "hhsearch"
                    }
                  }
                },
                "disk_image": {
                  "componentInputParameter": "datasets_disk_image"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "region": {
                  "componentInputParameter": "region"
                }
              }
            },
            "taskInfo": {
              "name": "Search Pdb"
            }
          },
          "importer": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-importer"
            },
            "inputs": {
              "parameters": {
                "uri": {
                  "componentInputParameter": "fasta_path"
                }
              }
            },
            "taskInfo": {
              "name": "importer"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "datasets_disk_image": {
            "type": "STRING"
          },
          "fasta_path": {
            "type": "STRING"
          },
          "project": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.11"
  },
  "runtimeConfig": {
    "parameters": {
      "datasets_disk_image": {
        "stringValue": "https://www.googleapis.com/compute/v1/projects/jk-mlops-dev/global/images/jk-alphafold-datasets 3000"
      },
      "project": {
        "stringValue": "jk-mlops-dev"
      },
      "region": {
        "stringValue": "us-central1"
      }
    }
  }
}