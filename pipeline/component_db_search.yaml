name: Db search
description: Searches sequence databases using the specified tool.
inputs:
- {name: project, type: String}
- {name: region, type: String}
- {name: disk_image, type: String}
- {name: database_paths, type: String}
- {name: db_tool, type: String}
- {name: input_data, type: Dataset}
outputs:
- {name: output_data, type: Dataset}
- {name: cls_logging, type: Artifact}
implementation:
  container:
    image: gcr.io/jk-mlops-dev/alphafold-components
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef db_search(\n    project: str,\n    region: str,\n    disk_image:\
      \ str,\n    database_paths: str,\n    db_tool: str,\n    input_data: Input[Dataset],\n\
      \    output_data: Output[Dataset],\n    cls_logging: Output[Artifact] \n   \
      \ ):\n    \"\"\"Searches sequence databases using the specified tool.\n\n  \
      \  This is a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n\
      \    We are using CLS as KFP does not support attaching pre-populated disks\
      \ or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch\
      \ or hhblits.\n\n    \"\"\"\n\n\n    import logging\n    import os\n\n    from\
      \ dsub_wrapper import run_dsub_job\n\n    # For a prototype we are hardcoding\
      \ some values. Whe productionizing\n    # we can make them compile time or runtime\
      \ parameters\n    # E.g. CPU type is important. HHBlits requires at least SSE2\
      \ instruction set\n    # Works better with AVX2. \n    # At runtime we could\
      \ pass them as tool_options dictionary\n\n    _TOOL_TO_SETTINGS_MAPPING = {\n\
      \       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n      \
      \     'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ':\
      \ '10_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT':\
      \ 'sto',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py'\
      \ \n       },\n       'hhblits': {\n           'MACHINE_TYPE': 'c2-standard-4',\n\
      \           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 4,\n           'MAXSEQ':\
      \ '1_000_000',\n           'INPUT_DATA_FORMAT': 'fasta',\n           'OUTPUT_DATA_FORMAT':\
      \ 'a3m',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py'\
      \ \n       },\n       'hhsearch': {\n           'MACHINE_TYPE': 'c2-standard-4',\n\
      \           'BOOT_DISK_SIZE': '200',\n           'N_CPU': 0, # Not setable for\
      \ hhsearch\n           'MAXSEQ': '1_000_000',\n           'INPUT_DATA_FORMAT':\
      \ 'sto',\n           'OUTPUT_DATA_FORMAT': 'hhr',\n           'SCRIPT': '/scripts/alphafold_components/alphafold_runners/db_search_runner.py'\
      \ \n       }\n    }\n\n    if not db_tool in _TOOL_TO_SETTINGS_MAPPING.keys():\n\
      \        raise ValueError(f'Unsupported tool: {db_tool}')\n    # We should probably\
      \ also do some checking whether a given tool, DB combination works\n\n    _DSUB_PROVIDER\
      \ = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _IMAGE = 'gcr.io/jk-mlops-dev/alphafold'\n\
      \n    output_data.metadata['data_format'] = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\
      \n    job_params = [\n        '--db_tool', db_tool,\n        '--machine-type',\
      \ _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size',\
      \ _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging',\
      \ cls_logging.uri,\n        '--mount', f'DB_ROOT={disk_image}',\n        '--input',\
      \ f'INPUT_DATA={input_data.uri}',\n        '--output', f'OUTPUT_DATA={output_data.uri}',\n\
      \        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      N_CPU\"]}',\n        '--env', f'INPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      INPUT_DATA_FORMAT\"]}', \n        '--env', f'OUTPUT_DATA_FORMAT={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      OUTPUT_DATA_FORMAT\"]}', \n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT']\
      \ \n    ]\n\n    return\n\n    result = run_dsub_job(\n        provider='google-cls-v2',\n\
      \        project=project,\n        regions=region,\n        params=job_params,\n\
      \    ) \n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - db_search
