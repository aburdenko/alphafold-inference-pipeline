name: Msa search
description: Searches sequence databases using the specified tool.
inputs:
- {name: project, type: String}
- {name: region, type: String}
- {name: msa_dbs, type: JsonArray}
- {name: reference_databases, type: Dataset}
- {name: sequence, type: Dataset}
outputs:
- {name: msa, type: Dataset}
- {name: cls_logging, type: Artifact}
implementation:
  container:
    image: gcr.io/jk-mlops-dev/alphafold-components
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.11' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef msa_search(\n    project: str,\n    region: str,\n    msa_dbs:\
      \ list,\n    reference_databases: Input[Dataset],\n    sequence: Input[Dataset],\n\
      \    msa: Output[Dataset],\n    cls_logging: Output[Artifact] \n    ):\n   \
      \ \"\"\"Searches sequence databases using the specified tool.\n\n    This is\
      \ a simple prototype using dsub to submit a Cloud Life Sciences pipeline.\n\
      \    We are using CLS as KFP does not support attaching pre-populated disks\
      \ or premtible VMs.\n    GCSFuse does not perform well with tools like hhsearch\
      \ or hhblits.\n\n    The prototype also lacks job control. If a pipeline step\
      \ fails, the CLS job can get \n    orphaned\n\n    \"\"\"\n\n    import logging\n\
      \    import os\n    import sys\n\n    from dsub_wrapper import run_dsub_job\n\
      \n    _UNIREF90 = 'uniref90'\n    _MGNIFY = 'mgnify'\n    _BFD = 'bfd'\n   \
      \ _UNICLUST30 = 'uniclust30'\n    _UNIPROT = 'uniprot'\n\n    _DSUB_PROVIDER\
      \ = 'google-cls-v2'\n    _LOG_INTERVAL = '30s'\n    _ALPHAFOLD_RUNNER_IMAGE\
      \ = 'gcr.io/jk-mlops-dev/alphafold'\n\n    _DEFAULT_FILE_PREFIX = 'datafile'\n\
      \n    # For a prototype we are hardcoding some values. Whe productionizing\n\
      \    # we can make them compile time or runtime parameters\n    # E.g. CPU type\
      \ is important. HHBlits requires at least SSE2 instruction set\n    # Works\
      \ better with AVX2. \n    # At runtime we could pass them as tool_options dictionary\n\
      \    logging.basicConfig(format='%(asctime)s - %(message)s',\n             \
      \         level=logging.INFO, \n                      datefmt='%d-%m-%y %H:%M:%S',\n\
      \                      stream=sys.stdout)\n\n    _TOOL_TO_SETTINGS_MAPPING =\
      \ {\n       'jackhmmer': {\n           'MACHINE_TYPE': 'n1-standard-4',\n  \
      \         'BOOT_DISK_SIZE': '200',\n           'OUTPUT_DATA_FORMAT': 'sto',\n\
      \           'N_CPU': 4,\n           'MAXSEQ': '10_000',\n           'SCRIPT':\
      \ '/scripts/alphafold_runners/jackhmmer_runner.py' \n       },\n       'hhblits':\
      \ {\n           'MACHINE_TYPE': 'c2-standard-4',\n           'BOOT_DISK_SIZE':\
      \ '200',\n           'OUTPUT_DATA_FORMAT': 'a3m',\n           'N_CPU': 4,\n\
      \           'MAXSEQ': '1_000_000',\n           'SCRIPT': '/scripts/alphafold_runners/hhblits_runner.py'\
      \ \n       },\n    }\n\n    # This is a temporary crude solution to map a the\
      \ list of databases to search\n    # to a search tool. In the prototype we assume\
      \ that the provided databases list \n    # can be searched with a single tool\n\
      \    _DATABASE_TO_TOOL_MAPPING = {\n        _UNIREF90: 'jackhmmer',\n      \
      \  _MGNIFY: 'jackhmmer',\n        _BFD: 'hhblits',\n        _UNICLUST30: 'hhblits',\
      \ \n        _UNIPROT: None, # to be determined\n    }\n\n    tools = [_DATABASE_TO_TOOL_MAPPING[db]\
      \ for db in msa_dbs\n              if _DATABASE_TO_TOOL_MAPPING[db]]\n    tools\
      \ = list(set(tools))\n\n    if (not tools) or (len(tools) > 1):\n        raise\
      \ RuntimeError(f'The database list {msa_dbs} not supported')\n    db_tool =\
      \ tools[0]\n\n    disk_image = reference_databases.metadata['disk_image']\n\
      \    database_paths = [reference_databases.metadata[database]\n            \
      \          for database in msa_dbs]\n    database_paths = ','.join(database_paths)\n\
      \n    output_data_format = _TOOL_TO_SETTINGS_MAPPING[db_tool]['OUTPUT_DATA_FORMAT']\n\
      \    msa.metadata['data_format'] = output_data_format\n    output_path = msa.uri\n\
      \    input_path = sequence.uri\n\n    job_params = [\n        '--machine-type',\
      \ _TOOL_TO_SETTINGS_MAPPING[db_tool]['MACHINE_TYPE'],\n        '--boot-disk-size',\
      \ _TOOL_TO_SETTINGS_MAPPING[db_tool]['BOOT_DISK_SIZE'],\n        '--logging',\
      \ cls_logging.uri,\n        '--log-interval', _LOG_INTERVAL, \n        '--image',\
      \ _ALPHAFOLD_RUNNER_IMAGE,\n        '--env', f'PYTHONPATH=/app/alphafold',\n\
      \        '--mount', f'DB_ROOT={disk_image}',\n        '--input', f'INPUT_PATH={input_path}',\n\
      \        '--output', f'OUTPUT_PATH={output_path}',\n        '--env', f'DB_TOOL={db_tool}',\n\
      \        '--env', f'DB_PATHS={database_paths}',\n        '--env', f'N_CPU={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      N_CPU\"]}',\n        '--env', f'MAXSEQ={_TOOL_TO_SETTINGS_MAPPING[db_tool][\"\
      MAXSEQ\"]}', \n        '--script', _TOOL_TO_SETTINGS_MAPPING[db_tool]['SCRIPT']\
      \ \n    ]\n\n    result = run_dsub_job(\n        provider=_DSUB_PROVIDER,\n\
      \        project=project,\n        regions=region,\n        params=job_params,\n\
      \    ) \n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - msa_search
